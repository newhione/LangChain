{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0233c168",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation (RAG)\n",
    "대규모 문서데이터베이스에서 관련 정보 검색 -> 더 정확하고 상세한 답변 가능\n",
    "\n",
    "\n",
    "8단계 프로세스   \n",
    "<사전 준비>\n",
    "- 1. 도큐먼트 로드(Document Loader): 외부 데이터 소스에서 필요한 **_데이터 로드 및 초기 처리_**\n",
    "- 2. 텍스트 분할(Text Splitter): 로드된 문서를 **_처리 가능한 작은 단위_(Chunk)** 로 분할\n",
    "- 3. 임베딩 (Embedding): 문서를 **_벡터 형태_** 로 변환 -> **문서의 의미 수치화**\n",
    "- 4. 벡터 스토어(Vector Store) 저장: 임베딩된 벡터들을 _데이터베이스에 저장_ \n",
    "\n",
    "<런타임>\n",
    "- 5. 검색기(Retriver): **질문** 주어짐 -> **관련 벡터 검색** in 데이터베이스  ->  유사도 검색(similarity, mmr), Multi-Query, Multi-Retriver\n",
    "        ```\n",
    "        Dense: 유사도 기반 검색, Sparse: 키워드 기반 검색\n",
    "        ```\n",
    "- 6. 프롬프트(Prompt): 검색된 정보를 바탕으로 **언어모델을 위한 질문 구성**\n",
    "- 7. LLM: 구성된 프롬프트를 사용해 언어모델이 답변 생성, **LLM 모델 정의**\n",
    "- 8. 체인(Chain): 위 단계를 하나의 _파이프라인_ 으로 묶음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c17e89",
   "metadata": {},
   "source": [
    "# 01. PDF 문서 기반 QA(Question-Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66bfef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce63355",
   "metadata": {},
   "source": [
    "### 0. 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8627b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skeleton code\n",
    "from langchain_community.document_loaders import PyMuPDFLoader #PDF-> doc각 페이지\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #기본 splitter\n",
    "from langchain_community.vectorstores import FAISS  #벡터 검색 라이브러리\n",
    "from langchain_core.prompts import PromptTemplate  #(LLM에게 보낼 프롬프트 -> 변수 넣는 템플릿) => 관리,재사용 용이\n",
    "from langchain_core.runnables import RunnablePassthrough #입력 그대로 전달\n",
    "from langchain_core.output_parsers import StrOutputParser  #LLM 응답에서 텍스트만 추출 -> str 타입으로 반환\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  #LangChain에 openai를 쉽게 불러올 수 있도록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a82501",
   "metadata": {},
   "source": [
    "### 1. Document 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430f6ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지 수: 23\n"
     ]
    }
   ],
   "source": [
    "# 1. 도큐먼트 로드\n",
    "# 준비\n",
    "loader = PyMuPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "# 단일 pdf파일 -> [페이지 수만큼 Document객체 리스트]\n",
    "documents = loader.load()\n",
    "\n",
    "print(f'문서의 페이지 수: {len(documents)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08fd2cd",
   "metadata": {},
   "source": [
    "Document 구조\n",
    "> ```txt\n",
    "> [\n",
    ">   Document(1페이지),\n",
    ">   Document(2페이지),\n",
    ">   Document(3페이지),\n",
    ">   ...\n",
    "> ]\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40deb798",
   "metadata": {},
   "source": [
    "### 2. 문서 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dd99bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의 수: 43\n"
     ]
    }
   ],
   "source": [
    "# 2. 문서 분할\n",
    "#청크의 최대 글자 수 #겹치는 글자 수->문맥 보존\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "# [페이지 단위 Documents] → [더 작은 chunk Documents]\n",
    "split_documents = text_splitter.split_documents(documents) # =chunk\n",
    "\n",
    "print(f'분할된 청크의 수: {len(split_documents)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ab996",
   "metadata": {},
   "source": [
    "split_documents 구조\n",
    "> ```txt\n",
    "> [\n",
    ">   Document(1페이지의 chunk1),\n",
    ">   Document(1페이지의 chunk2),\n",
    ">   Document(2페이지의 chunk1),\n",
    ">   Document(3페이지의 chunk1),\n",
    ">   Document(3페이지의 chunk2),\n",
    ">   ...\n",
    "> ]\n",
    "> ```\n",
    "> 단순 텍스트 목록, 검색 불가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8dcdab",
   "metadata": {},
   "source": [
    "### 4. 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a275056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 임베딩\n",
    "    # 벡터화\n",
    "    # chunk를 '의미 기반'의 고차원 벡터로 변환  (의미 기반 검색 o -> 의미유사도  /  키워드 검색 X)\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac44aa",
   "metadata": {},
   "source": [
    "embeddings 구조\n",
    "> ```txt\n",
    "> [\n",
    ">   [0.123, -0.019, 0.772, ... 1536개],\n",
    ">   [0.551, 0.214, -0.488, ...],\n",
    ">   ...\n",
    "> ]\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97a576",
   "metadata": {},
   "source": [
    "### 4. 벡터스토어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b7d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create DB 및 저장\n",
    "    # 벡터 스토어 생성\n",
    "    # 벡터들을 FAISS 인덱스에 저장\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff3742",
   "metadata": {},
   "source": [
    "FAISS 인덱스 구조 (단순 리스트 → 벡터 검색 가능한 DB)\n",
    "> ```txt\n",
    "> vector index:\n",
    ">   [\n",
    ">     (id=0, vector=chunk1_vector),\n",
    ">     (id=1, vector=chunk2_vector),\n",
    ">     (id=2, vector=chunk3_vector),\n",
    ">     ...\n",
    ">   ]\n",
    "> ```\n",
    "> 청크가 벡터로 저장되어 의미 기반 검색 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf63204",
   "metadata": {},
   "source": [
    "### 5. Retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d4c6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Retriver 생성 (문서에 포함되어 있는 정보를 검색하고 생성 = 벡터 DB에서 “질문과 의미적으로 가까운 청크”를 찾아주는 검색기)\n",
    "retriever = vectorstore.as_retriever()   #FAISS 벡터DB → RAG 검색기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4a4247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='3f75006f-7f53-44f7-b59c-44d35365765d', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 19}, page_content='페이스의  제퍼(Zephyr-7b)가 라마2를 능가\\n<갈릴레오의 LLM 환각 지수(RAG 포함 질문과 답변 기준)>\\n☞ 출처: Galileo, LLM Hallucination Index, 2023.11.15.'),\n",
       " Document(id='aef7d271-67d2-4ea5-a8d9-f35884ceeeea', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 19}, page_content='1. 정책/법제  \\n2. 기업/산업 \\n3. 기술/연구 \\n 4. 인력/교육\\n갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수\\nn 주요 LLM의 환각 현상을 평가한 ‘LLM 환각 지수’에 따르면 GPT-4는 작업 유형과 관계없이 \\n가장 우수한 성능을 보였으며 GPT-3.5도 거의 동등한 성능을 발휘\\nn 오픈소스 모델 중에서는 메타의 라마2가 RAG 없는 질문과 답변 및 긴 형식의 텍스트 \\n생성에서 가장 우수한 성능을 발휘\\nKEY Contents\\n£ 주요 LLM 중 GPT-4가 가장 환각 현상 적고 GPT-3.5 터보도 비슷한 성능 기록\\nn 머신러닝 데이터 관리 기업 갈릴레오(Galileo)가 2023년 11월 15일 주요 LLM의 환각 현상을 평가한 \\n‘LLM 환각 지수(LLM Hallucination Index)’를 발표\\n∙생성 AI의 환각 현상은 AI 시스템이 잘못된 정보를 생성하거나, 현실과 다른 부정확한 결과를 내놓는 \\n현상으로, 기업의 AI 도입을 가로막는 주요 장애물이며, 환각 지수는 신뢰할 수 있는 생성 AI 구축을 위해 \\n환각을 평가하고 측정하는 구조화된 접근방식을 제공\\n∙환각 지수는 △검색 증강 생성(Retrieval-Augmented Generation, RAG)*을 포함한 질문과 답변 △RAG \\n없는 질문과 답변 △긴 형식의 텍스트(보고서나 기사, 에세이) 생성의 3개 작업 유형에 대하여 환각을 \\n기준으로 LLM의 순위를 평가\\n* 기존에 학습된 데이터가 아닌 외부 소스(데이터셋, 데이터베이스, 문서 등)에서 가져온 정보를 검색해 활용하는 기술\\nn 3개의 작업 유형 평가 전체에서 오픈AI의 GPT-4가 최고의 성능을 기록했으며, GPT-3.5 터보도 \\nGPT-4와 거의 동등한 성능을 발휘\\n∙메타의 라마2(Llama-2-70b)는 RAG 없는 질문과 답변 유형에서 오픈소스 모델 가운데 가장 우수했고 긴 \\n형식의 텍스트 생성에서도 GPT-4에 준하는 성능을 기록했으나, RAG 포함 질문과 답변에서는 허깅'),\n",
       " Document(id='33c9d11f-83db-4d67-b3fc-99028645667e', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 12}, page_content='2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글 \\n어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.'),\n",
       " Document(id='f22fa5af-be24-4b39-978e-d1cbb910cb14', metadata={'producer': 'Hancom PDF 1.3.0.542', 'creator': 'Hwp 2018 10.0.0.13462', 'creationdate': '2023-12-08T13:28:38+09:00', 'source': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'file_path': 'data/SPRI_AI_Brief_2023년12월호_F.pdf', 'total_pages': 23, 'format': 'PDF 1.4', 'title': '', 'author': 'dj', 'subject': '', 'keywords': '', 'moddate': '2023-12-08T13:28:38+09:00', 'trapped': '', 'modDate': \"D:20231208132838+09'00'\", 'creationDate': \"D:20231208132838+09'00'\", 'page': 21}, page_content='행사명\\n행사 주요 개요\\nCES 2024\\n- 미국 소비자기술 협회(CTA)가 주관하는 세계 최대 가전·IT·소\\n비재 전시회로 5G, AR&VR, 디지털헬스, 교통·모빌리티 등 \\n주요 카테고리 중심으로 기업들이 최신의 기술 제품군을 전시\\n- CTA 사피로 회장은 가장 주목받는 섹터로 AI를 조명하였으며, \\n모든 산업을 포괄한다는 의미에서 ‘올 온(All on)’을 주제로 한 \\n이번 전시에는 500곳 이상의 한국기업 참가 예정\\n기간\\n장소 \\n홈페이지\\n2024.1.9~12\\n미국, 라스베가스\\nhttps://www.ces.tech/\\nAIMLA 2024\\n- 머신러닝 및 응용에 관한 국제 컨퍼런스(AIMLA 2024)는 \\n인공지능 및 머신러닝의 이론, 방법론 및 실용적 접근에 관한 \\n지식과 최신 연구 결과 공유\\n- 이론 및 실무 측면에서 인공지능, 기계학습의 주요 분야를 \\n논의하고, 학계, 산업계의 연구자와 실무자들에게 해당 분\\n야의 최첨단 개발 소식 공유\\n기간\\n장소 \\n홈페이지\\n2024.1.27~28\\n덴마크, 코펜하겐\\nhttps://ccnet2024.org/aimla\\n/index\\nAAAI Conference \\non Artificial \\nIntelligence\\n- AI 발전 협회 컨퍼런스(AAAI)는 AI 연구를 촉진하고, AI 분야 \\n연구원, 실무자, 과학자, 학생 및 공학자 간 교류의 기회 제공\\n- 컨퍼런스에서 AI 관련 기술 발표, 특별 트랙, 초청 연사, \\n워크숍, 튜토리얼, 포스터 세션, 주제 발표, 대회, 전시 프\\n로그램 등 진행   \\n기간\\n장소 \\n홈페이지\\n2024.2.20~27\\n캐나다, 밴쿠버\\nhttps://aaai.org/aaai-confere\\nnce/\\nⅡ. 주요 행사 일정')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriver에 쿼리를 날려, chunk 결과 확인하기\n",
    "retriever.invoke('메타의 라마에 대해 설명해주세요')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56069fd5",
   "metadata": {},
   "source": [
    "`page_content` → LLM에게 넘겨질 실제 텍스트   \n",
    "`metadata` → 출처/페이지/청크 번호 정보"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726127f",
   "metadata": {},
   "source": [
    "### 6. 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6a74c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 프롬프트 생성\n",
    "    # LLM이 답변을 생성할 수 있게, _입력 구조를 정형화_하는 단계\n",
    "prompt = PromptTemplate.from_template( \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Answer in Korean.\n",
    "\n",
    "#Question(query): \n",
    "{question} \n",
    "#Context(response):  \n",
    "{context} \n",
    "\n",
    "#Answer정확하게 답변하세요:\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd209e0",
   "metadata": {},
   "source": [
    "`PromptTemplate.from_template()` -> \"내가 만든 문자열을 *템플릿*으로 변환해줘\"\n",
    "- 자유 형식 템플릿\n",
    "- #Question: #Context: 구조는 이렇다고 사람이 이해하기 쉽게 만든 포맷일뿐임\n",
    "- 템플릿 안에 변수명 필수: `{QUestion}` `{Context}`\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785445af",
   "metadata": {},
   "source": [
    "### 7. LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e21e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. LLM 생성\n",
    "llm = ChatOpenAI(model='gpt-5-nano', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2744d2",
   "metadata": {},
   "source": [
    "### 8. Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a2dd320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Chain 생성\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()} #사용자 흐름 참고\n",
    "    | prompt  #최종 프롬프트\n",
    "    | llm  #llm에 전달 -> 답변 생성\n",
    "    | StrOutputParser()  #output을 str로 보기좋게\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c1b21b",
   "metadata": {},
   "source": [
    "사용자 흐름\n",
    "1. `chain.invoke(\"메타의 라마 뭐야?\")`\n",
    "2. \"question\"에는 사용자의 질문이 그대로 들어감\n",
    "3. → `RunnablePassthrough()`는 “그대로 통과시키기” 역할\n",
    "4. \"context\"에는 `retriever`가 검색한 chunk들이 자동으로 들어감"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66511f0",
   "metadata": {},
   "source": [
    "### Test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea46dd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주어진 컨텍스트에는 애플과 삼성의 비교에 대한 정보가 없습니다. 따라서 “삼성보단 애플이 짱이다”라는 주장에 대해 확인하거나 근거를 제시할 수 없습니다.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체인 실행!\n",
    "    # 문서에 대한 질문 입력 -> 답변 출력\n",
    "question = \"삼성보단 애플이 짱이지\"\n",
    "\n",
    "response = chain.invoke(question)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de75ed0f",
   "metadata": {},
   "source": [
    "> `question` = 사용자가 입력하는 질문 (자연어 질문)   \n",
    "> `query` = retriever 입장에서 검색 요청\n",
    "\n",
    "> `context` = retriever가 찾은 문서 청크   \n",
    "> `response` = LLM이 만든 최종 답변\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181369f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
